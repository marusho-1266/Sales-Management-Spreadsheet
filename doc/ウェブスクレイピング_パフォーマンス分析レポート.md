# ウェブスクレイピング機能 パフォーマンス分析レポート

**作成日**: 2026-01-13  
**分析対象**: `inventory_scraper/` 実装

---

## 1. 実行概要

ウェブスクレイピング実行時の実行時間が長い問題について、コードを分析し、パフォーマンスに影響を与えている可能性のある機能を特定しました。

---

## 2. 重大なパフォーマンス問題

### 🔴 問題1: URLごとにスプレッドシート設定を読み込む（最優先対応）

**影響度**: ⭐⭐⭐⭐⭐（極めて高い）

**問題の詳細**:
- `scraper.py`の`get_scraper()`関数が、**各URLごとに**`ScraperConfigLoader`を新規作成
- `ScraperConfigLoader`の初期化時に、スプレッドシートから設定を読み込もうとする
- スプレッドシート設定読み込み時に、**GID 0-20まで順次試行**（最大21回のダウンロード）
- 各ダウンロード試行で**3秒の待機時間**

**影響**:
- 100件のURLを処理する場合、最大で**2,100回のダウンロード試行**（21回 × 100URL）
- 最悪の場合、**6,300秒（105分）**の待機時間が発生する可能性

**該当コード**:
```python
# scraper.py:333-355行目
def get_scraper(url: str, browser) -> BaseScraper:
    # 各URLごとに新規作成される
    config_loader = ScraperConfigLoader(browser=browser, use_spreadsheet=True)
    # ...
```

```python
# spreadsheet_config_loader.py:44-112行目
def _download_supplier_master_csv(self) -> pd.DataFrame:
    possible_gids = [str(i) for i in range(21)]  # 0-20まで
    for gid in possible_gids:
        # 各GIDで3秒待機
        time.sleep(3)
        # CSVダウンロード試行
```

**推奨対応**:
- `ScraperConfigLoader`を**1回だけ作成**し、全URLで再利用する
- または、スプレッドシート設定読み込みを**オプション化**し、デフォルトはJSON設定ファイルのみを使用

---

### 🟡 問題2: デバッグ機能の自動実行

**影響度**: ⭐⭐⭐⭐（高い）

**問題の詳細**:
- 価格が見つからない場合に、`_debug_price_elements()`が**自動実行**される
- ページ内の全要素を検索するため、**非常に時間がかかる**
- デバッグ情報は通常の運用では不要

**影響**:
- 価格取得に失敗したURLごとに、追加で**5-10秒**の処理時間が発生

**該当コード**:
```python
# configurable_scraper.py:60-62行目
if price:
    result['仕入れ価格'] = price
else:
    result['仕入れ価格'] = -1
    # デバッグ: 価格が見つからなかった場合、ページ内の価格要素を探す
    print(f"  警告: 価格が見つかりませんでした。デバッグ情報を出力します...")
    self._debug_price_elements(url)  # ← 自動実行される
```

**推奨対応**:
- デバッグ機能を**環境変数やフラグで制御**できるようにする
- デフォルトは**無効**にし、必要な場合のみ有効化

---

### 🟡 問題3: 過剰なデバッグログ出力

**影響度**: ⭐⭐⭐（中程度）

**問題の詳細**:
- 各セレクタの試行状況を詳細に出力
- 価格抽出の各ステップでprint文が実行される
- I/Oオーバーヘッドが発生

**影響**:
- 大量のログ出力により、**I/O待機時間**が発生
- 100件のURLで、数千行のログが出力される可能性

**該当コード**:
```python
# configurable_scraper.py:170-260行目
print(f"  価格セレクタを試行中: {len(selectors)}個のセレクタ")
for selector in selectors:
    print(f"    セレクタ '{selector}': 要素が見つかりませんでした")
    print(f"    セレクタ '{selector}': {len(elements)}個の要素が見つかりました")
    print(f"      価格を発見: {price}円 (テキスト: {price_text[:50]})")
    # ... 多数のprint文
```

**推奨対応**:
- ログレベルを設定し、**詳細ログはDEBUGレベル**に変更
- デフォルトは**INFOレベル**のみ出力

---

### 🟢 問題4: フォールバック処理の重複実行

**影響度**: ⭐⭐（低～中程度）

**問題の詳細**:
- `get_scraper()`関数内で、複数箇所で同じ設定ファイル読み込み処理が実行される可能性がある
- 同じURLパターンで複数回`ScraperConfigLoader`が作成される

**該当コード**:
```python
# scraper.py:333-406行目
# 最初に設定ファイルベースのスクレイパーを試す（1回目）
config_loader = ScraperConfigLoader(browser=browser, use_spreadsheet=True)

# Yahoo!オークションの場合（2回目）
config_loader = ScraperConfigLoader(browser=browser, use_spreadsheet=True)

# その他のYahoo!サイトの場合（3回目）
config_loader = ScraperConfigLoader(browser=browser, use_spreadsheet=True)

# デフォルトの場合（4回目）
config_loader = ScraperConfigLoader(browser=browser, use_spreadsheet=True)
```

**推奨対応**:
- `ScraperConfigLoader`を**1回だけ作成**し、全URLで再利用

---

## 3. その他の最適化可能な点

### 3.1 待機時間の最適化

**現状**:
- 各URLで3-7秒のランダム待機（これは必要だが、他の最適化で相対的に影響が小さくなる）

**推奨**:
- 他の最適化を優先し、待機時間は現状維持

### 3.2 価格抽出のフォールバック処理

**現状**:
- すべてのセレクタで見つからない場合、`_extract_max_price_from_all_elements()`が実行される
- ページ内の全要素を検索するため、時間がかかる

**推奨**:
- フォールバック処理は**最後の手段**として残す
- デバッグモードでのみ詳細ログを出力

---

## 4. 推奨される最適化の優先順位

### 優先度1（最優先）: 設定読み込みの最適化
- **問題1**の対応: `ScraperConfigLoader`を1回だけ作成し、全URLで再利用
- **期待される効果**: 実行時間を**90%以上短縮**（100件のURLで105分 → 10分以下）

### 優先度2: デバッグ機能の無効化
- **問題2**の対応: デバッグ機能を環境変数で制御可能にし、デフォルトは無効
- **期待される効果**: 価格取得失敗時の処理時間を**50%短縮**

### 優先度3: ログレベルの最適化
- **問題3**の対応: 詳細ログをDEBUGレベルに変更
- **期待される効果**: I/O待機時間を**30%短縮**

### 優先度4: コードの整理
- **問題4**の対応: 重複処理の削除
- **期待される効果**: コードの保守性向上、わずかなパフォーマンス改善

---

## 5. 実装不要と思われる機能

### 5.1 スプレッドシート設定読み込みの自動実行
- **現状**: デフォルトでスプレッドシートから設定を読み込もうとする
- **問題**: URLごとに実行されるため、極めて非効率
- **推奨**: 
  - デフォルトは**JSON設定ファイルのみ**を使用
  - スプレッドシート設定読み込みは**オプション**として、必要な場合のみ有効化

### 5.2 デバッグ機能の自動実行
- **現状**: 価格が見つからない場合に自動実行
- **問題**: 通常の運用では不要な処理が実行される
- **推奨**: 
  - デバッグ機能は**環境変数で制御**可能にし、デフォルトは無効
  - 必要な場合のみ有効化

### 5.3 過剰なデバッグログ
- **現状**: 各セレクタの試行状況を詳細に出力
- **問題**: I/Oオーバーヘッドが発生
- **推奨**: 
  - 詳細ログは**DEBUGレベル**に変更
  - デフォルトは**INFOレベル**のみ出力

---

## 6. まとめ

### 実行時間が長い主な原因

1. **URLごとにスプレッドシート設定を読み込む**（最優先対応）
   - 100件のURLで最大105分の待機時間が発生する可能性
   - **即座に対応が必要**

2. **デバッグ機能の自動実行**
   - 価格取得失敗時に追加で5-10秒の処理時間が発生
   - **優先的に対応が必要**

3. **過剰なデバッグログ出力**
   - I/O待機時間が発生
   - **対応により改善が期待できる**

### 期待される改善効果

- **問題1の対応**: 実行時間を**90%以上短縮**
- **問題2の対応**: 価格取得失敗時の処理時間を**50%短縮**
- **問題3の対応**: I/O待機時間を**30%短縮**

**総合的な改善効果**: 実行時間を**80-90%短縮**することが期待できます。

---

## 7. 次のステップ

1. **問題1の対応**を最優先で実装
2. **問題2の対応**を実装
3. **問題3の対応**を実装
4. 実装後のパフォーマンステストを実施
